{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP5 : Reconnaissance d'image par un réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na-Yck4lZiN1"
   },
   "source": [
    "### Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1606831889555,
     "user": {
      "displayName": "Stephan Semirat",
      "photoUrl": "",
      "userId": "06413469689434144964"
     },
     "user_tz": -60
    },
    "id": "Zupdaax6Xf8b"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3  X4  X5  X6  X7  X8  X9  Y\n",
       "0   0   0   1   1   0   0   1   0   1  0\n",
       "1   0   1   1   0   1   0   1   1   0  1\n",
       "2   1   1   0   0   1   1   1   0   1  1\n",
       "3   0   0   0   1   1   1   0   0   1  0\n",
       "4   1   0   1   1   1   0   1   0   0  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture des données\n",
    "DIAGONAL=pd.read_csv(\"deuxdiag.csv\")\n",
    "# Visualisation des 5 premières données\n",
    "DIAGONAL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "1. Dans le jeu de données `DIAGONAL`, à quoi correspond une donnée ?\n",
    "2. On considère les données `X1`, ..., `X9` comme les 9 cases d'un carré 3*3 :<br/>\n",
    "    X1 X2 X3<br/>\n",
    "    X4 X5 X6<br/>\n",
    "    X7 X8 X9<br/>\n",
    "    À quelle condition sur les `Xi` a-t-on : une des deux diagonales du carré est constituée de 1 ?\n",
    "3. Vérifier sur les 5 premières données que le jeux de données `DIAGONAL` est tel que la conditon précédente est vérifiée si et seulement si `Y=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données d'apprentissage et données de validation\n",
    "\n",
    "Le jeu de données est séparé 2 :\n",
    "- Deux tiers des données sont utilisées pour l'apprentissage du réseau de neurones\n",
    "- Le troisième tiers des données est mis à l'écart et sera utilisé pour évaluer la performance du réseau sur ces données (sur lesquelles il n'aura pas appris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(DIAGONAL) # Nombre de données\n",
    "n=int(2*N/3) # Deux tiers du nombres de données \n",
    "X=DIAGONAL.drop(['Y'],axis=1)[0:n] # Données d'apprentissage X\n",
    "Y=DIAGONAL['Y'][0:n] # Données d'apprentissage Y\n",
    "X.insert(loc = 0, column = 'X0',value = np.ones(n,dtype = int)) # On ajoute une colonne de 1 pour b\n",
    "Xvalid=DIAGONAL.drop(['Y'],axis=1)[n+1:N] # Données de validation X\n",
    "Yvalid=DIAGONAL['Y'][n+1:N] # Données de validation Y\n",
    "nvalid=len(Xvalid)\n",
    "Xvalid.insert(loc = 0, column = 'X0',value = np.ones(nvalid,dtype=int)) # On ajoute une colonne de 1 pour b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Sachant que `DIAGONAL` contient 150 données $(X_i,Y_i)$, sur combien de données le réseau va-t-il apprendre ? Sur combien de données la performance du réseau va-t-elle être évaluée ?\n",
    "\n",
    "Que contiennent les variables `X` et `Y` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau à 1 couche cachée de 2 neurones\n",
    "On approxime $X\\mapsto Y$ par la fonction $R_{\\mathcal{W}}$, où $\\mathcal{W}$ désigne l'ensemble des paramètres $b$, $w_1$, $w_2$, $B=\\begin{pmatrix}b_1\\\\b_2\\end{pmatrix}$ et $W=\\begin{pmatrix}W_1\\\\W_2\\end{pmatrix}=\\begin{pmatrix}w_{11}&w_{12}&\\ldots&w_{19}\\\\w_{21}&w_{22}&\\ldots&w_{29}\\end{pmatrix}$, définie par : $$R_{\\mathcal{W}}:X\\mapsto \\sigma\\left(b+\\begin{pmatrix}w_1&w_2\\end{pmatrix}\\cdot H(B+W\\cdot X)\\right),$$ où\n",
    "$$\\sigma(x)=\\frac{1}{1+e^{-x}}$$ est la fonction sigmoïde, et $$H=\\begin{pmatrix}h_1(X)\\\\h_2(X)\\end{pmatrix}=\\begin{pmatrix}\\sigma\\left(b_1+\\begin{pmatrix}w_{11}&\\ldots&w_{19}\\end{pmatrix}\\cdot X\\right)\\\\\\sigma\\left(b_2+\\begin{pmatrix}w_{21}&\\ldots&w_{29}\\end{pmatrix}\\cdot X\\right)\\end{pmatrix}$$ est la couche cachée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "1. Combien de paramètres la fonction $R_{\\mathcal{W}}$ possède-t-elle ?\n",
    "2. Représenter le réseau de neurones associé à $R_{\\mathcal{W}}$.\n",
    "3. Pourquoi parle-t-on d'un réseau à *deux* neurones ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rétropropagation du gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres $\\mathcal{W}$ sont déterminés en minimisant la fonction :\n",
    "$$f(\\mathcal{W})=\\frac{1}{2}\\sum\\limits_{j} (R_{\\mathcal{W}}(X_j)-Y_j)^2$$\n",
    "où la somme est calculée sur les données d'apprentissage.\n",
    "\n",
    "On réécrit $$f(\\mathcal{W})=\\frac{1}{2}\\sum\\limits_{j} (\\sigma(s_j)-Y_j)^2$$\n",
    "où $$s_j=b+\\begin{pmatrix}w_1&w_2\\end{pmatrix}\\cdot H_j,$$\n",
    "avec $$H_j=\\begin{pmatrix}\\sigma(h_{1j})\\\\ \\sigma(h_{2j})\\end{pmatrix}$$\n",
    "où $$h_{ij}=b_i+W_i\\cdot X_j.$$\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "On rappelle la propriété $\\sigma'(x)=\\sigma(x)\\times (1-\\sigma(x))$.\n",
    "\n",
    "1. À partir de $$f(\\mathcal{W})=\\frac{1}{2}\\sum\\limits_{j} (\\sigma(\\underbrace{b+\\begin{pmatrix}w_1&w_2\\end{pmatrix}\\cdot H_j}_{s_j})-Y_j)^2$$ établir les dérivées suivantes :\n",
    "    - $\\frac{\\partial f(\\mathcal{W})}{\\partial b}=\\sum\\limits_{j} (\\sigma(s_j)-Y_j)\\sigma(s_j)(1-\\sigma(s_j))\\times1$\n",
    "    - $\\frac{\\partial f(\\mathcal{W})}{\\partial w_i}=\\sum\\limits_{j} (\\sigma(s_j)-Y_j)\\sigma(s_j)(1-\\sigma(s_j))\\sigma(h_{ij})$\n",
    "\n",
    "2. À partir de $$f(\\mathcal{W})=\\frac{1}{2}\\sum\\limits_{j} (\\sigma(\\underbrace{b+w_1\\sigma(\\underbrace{b_1+\\sum\\limits_{k=1..9} w_{1k}x_{kj}}_{h_{1j}})+w_2\\sigma(\\underbrace{b_2+\\sum\\limits_{k=1..9} w_{2k}x_{kj}}_{h_{2j}})}_{s_j})-Y_j)^2$$ établir les dérivées suivantes :\n",
    "    - $\\frac{\\partial f(\\mathcal{W})}{\\partial b_i}=\\sum\\limits_{j} (\\sigma(s_j)-Y_j)\\sigma(s_j)(1-\\sigma(s_j)w_i\\sigma(h_{ij})(1-\\sigma(h_{ij}))\\times 1$\n",
    "    - $\\frac{\\partial f(\\mathcal{W})}{\\partial w_{ik}}=\\sum\\limits_{j} (\\sigma(s_j)-Y_j)\\sigma(s_j)(1-\\sigma(s_j))w_i\\sigma(h_{ij})(1-\\sigma(h_{ij}))x_{kj}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    H1=[sigma(np.dot(W[1],X.iloc[j])) for j in range(n)] # liste des sigma(h1j)\n",
    "    H2=[sigma(np.dot(W[2],X.iloc[j])) for j in range(n)] # liste des sigma(h2j)\n",
    "    S=[sigma(W[0][0]+W[0][1]*H1[j]+W[0][2]*H2[j]) for j in range(n)] # liste des sigma(sj)\n",
    "    return np.sum([(S[j]-Y[j])**2 for j in range(n)])\n",
    "\n",
    "def sigma(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Calcul du gradient\n",
    "def gradient(W): #W=[[b,w1,w2],[b1,w11,w12,...,w19],[b2,w21,...,w29]]\n",
    "    H1=[sigma(np.dot(W[1],X.iloc[j])) for j in range(n)] # liste des sigma(h1j)\n",
    "    H2=[sigma(np.dot(W[2],X.iloc[j])) for j in range(n)] # liste des sigma(h2j)\n",
    "    S=[sigma(W[0][0]+W[0][1]*H1[j]+W[0][2]*H2[j]) for j in range(n)] # liste des sigma(sj)\n",
    "    delta=[(S[j]-Y.iloc[j])*S[j]*(1-S[j]) for j in range(n)] # liste des produits utilisés\n",
    "    # Dérivées partielles :\n",
    "    db=np.sum([delta[j] for j in range(n)])\n",
    "    dw1=np.sum([delta[j]*H1[j] for j in range(n)])\n",
    "    dw2=np.sum([delta[j]*H2[j] for j in range(n)])\n",
    "    d1=[delta[j]*W[0][1]*H1[j]*(1-H1[j]) for j in range(n)] # liste de produits très utilisés\n",
    "    d2=[delta[j]*W[0][2]*H2[j]*(1-H2[j]) for j in range(n)] # liste de produits très utilisés\n",
    "    db1=np.sum([d1[j] for j in range(n)])\n",
    "    db2=np.sum([d2[j] for j in range(n)])\n",
    "    dW1=[0,0,0,0,0,0,0,0,0]\n",
    "    dW2=[0,0,0,0,0,0,0,0,0]\n",
    "    for k in range(9):\n",
    "        dW1[k]=np.sum([d1[j]*X.iloc[j][k] for j in range(n)])\n",
    "        dW2[k]=np.sum([d2[j]*X.iloc[j][k] for j in range(n)])\n",
    "    return [[db,dw1,dw2],[db1]+dW1,[db2]+dW2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercice***\n",
    "\n",
    "1. Calculer (dans la cellule ci-dessous) le gradient de $f$ pour des paramètres tous nuls : $\\mathcal{W}_0=(0,\\ldots,0)$.\n",
    "2. En déduire les coordonnées du point $\\mathcal{W}_1$ après une première itération de la descente de gradient pour un pas de $\\tau=10$.\n",
    "3. Calculer le gradient en $\\mathcal{W}_1$. Que remarquez vous ? Comment l'expliquer ?\n",
    "4. Est-ce judicieux de partir de $\\mathcal{W}_0$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculs :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithme de descente\n",
    "def descente(W,tau=1,tolerance=1e-3,Nbiterations=10):\n",
    "    for i in range(Nbiterations):\n",
    "        g = gradient(W)\n",
    "        normg = g[0][0]**2+g[0][1]**2+g[0][2]**2\n",
    "        +np.sum([g[1][k]**2 for k in range(10)])\n",
    "        +np.sum([g[2][k]**2 for k in range(10)])\n",
    "        print('g:',normg) # On affiche la norme du gradient pour visualiser la descente\n",
    "        print('f:',f(W))\n",
    "        if normg<tolerance:\n",
    "            print('L\\'algorithme a convergé.\\n Solution atteinte:\\n W=',W,'\\n Norme du gradient:',normg)\n",
    "            return W\n",
    "        W[0][0]=W[0][0]-tau*g[0][0]\n",
    "        W[0][1]=W[0][1]-tau*g[0][1]\n",
    "        W[0][2]=W[0][2]-tau*g[0][2]\n",
    "        for j in range(10):\n",
    "            W[1][j]=W[1][j]-tau*g[1][j]\n",
    "            W[2][j]=W[2][j]-tau*g[2][j]\n",
    "    print('L\\'algorithme n\\'a pas convergé.\\n Solution atteinte:\\n W=',W,'\\n Norme du gradient:',normg)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercice***\n",
    "\n",
    "Identifier la monotonie de l'algorithme sur les 10 premières itérations, à partir de \n",
    "\n",
    "`W=[[0,0,1],[0,0,0,1,0,1,1,0,1,0],[0,1,0,0,0,1,1,0,1,0]]`\n",
    "\n",
    "pour un pas de :\n",
    "- $\\tau=0.1$, avec une tolérance de $10^{-10}$ \n",
    "- $\\tau=1$, avec une tolérance de $10^{-10}$\n",
    "- $\\tau=2$, avec une tolérance de $10^{-20}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g: 184.02878287905696\n",
      "f: 37.051174795318545\n",
      "g: 1.13608433840083e-11\n",
      "f: 27.999994869855676\n",
      "L'algorithme a convergé.\n",
      " Solution atteinte:\n",
      " W= [[-8.929644821667454, -7.2432946299827305, -6.198951947414842], [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [-1.2303373644099542, -0.23033736440995423, -0.30526067724020306, -0.5423819063269736, -0.4731645085867943, 0.4935965252249378, 0.6852701072378768, -0.4072848497373618, 0.4960288540003609, -0.4385947514682201]] \n",
      " Norme du gradient: 1.13608433840083e-11\n"
     ]
    }
   ],
   "source": [
    "#Calculs\n",
    "W=[[0,0,1],[0,0,0,1,0,1,1,0,1,0],[0,1,0,0,0,1,1,0,1,0]]\n",
    "W=descente(W,1,1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "    \n",
    "Calculer, à l'aide de la fonction `prediction` ci-dessous, la sortie du réseau de neurones pour une valeur $X$ possèdant une diagonale de $1$ et pour une valeur de $X$ ne possédant pas une diagonale de $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(W,X):\n",
    "    return sigma(W[0][0]+W[0][1]*sigma(np.dot(W[1],X))+W[0][2]*sigma(np.dot(W[2],X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrer le W trouvé par l'algorithme de descente ci-dessus\n",
    "W= ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# entrer un X possédant ou ne possédant pas de diagonale de 1 \n",
    "# attention à insérer un 1 avant les 9 coordonnées de X, correspondant à l'ajout de b\n",
    "# dans le produit W.X\n",
    "print(prediction(W,...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation du modèle\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "À l'aide de la fonction suivante, déterminer le nombre d'erreurs du réseau de neurones paramétré par le `W` de l'exercice précédent, calculé sur les données de validations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'erreurs sur les 49 données de validation : 9.0\n"
     ]
    }
   ],
   "source": [
    "print('Nombre d\\'erreurs sur les',len(Xvalid),'données de validation :',\n",
    "      np.sum([np.abs(round(prediction(W,Xvalid.iloc[i]))-Yvalid.iloc[i])\n",
    "              for i in range(len(Xvalid)-1)])\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "Refaire le calcul précédent (validation du modèle) en utilisant le vecteur de paramètres :\n",
    "\n",
    "`W= [[8.151766727885503, -18.884915909234774, 20.58237721518839], [12.461460129290158, 1.0068383415839224, 0.6124931603260179, -5.6633462093648435, 0.31937922293433985, -5.499323198858325, 1.1547050495924607, -5.986379875948584, 0.08814543368440875, 1.8230438209745343], [-18.262720764933253, 6.653699501004856, -0.041561815642582586, 0.7187311299131572, 0.7479057784712368, 7.456783033416534, 0.18723100788706293, 0.9007878917526597, 0.26682037735546293, 6.687905945851743]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation d'une librairie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX=DIAGONAL.drop(['Y'],axis=1)[0:n] # Données d'apprentissage X\n",
    "YY=DIAGONAL['Y'][0:n] # Données d'apprentissage Y\n",
    "XXvalid=DIAGONAL.drop(['Y'],axis=1)[n+1:N] # Données de validation X\n",
    "YYvalid=DIAGONAL['Y'][n+1:N] # Données de validation Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele = MLPClassifier(\n",
    "    activation='logistic',\n",
    "    solver='sgd', # sgd=\"stochastic gradient descent\", #essayer avec lbfgs, ou adam à la place\n",
    "    shuffle=True,\n",
    "    hidden_layer_sizes=(2,),\n",
    "    max_iter=5000,\n",
    "    tol=1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modele.fit(XX,YY)\n",
    "print('Score : ',modele.score(XXvalid,YYvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=[[modele.intercepts_[1][0]]+[modele.coefs_[1][0][0]]+[modele.coefs_[1][1][0]],\\\n",
    "[modele.intercepts_[0][0]]+[modele.coefs_[0][k][0] for k in range(9)],\\\n",
    "[modele.intercepts_[0][1]]+[modele.coefs_[0][k][1] for k in range(9)]]\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Nb d\\'erreurs :',np.sum(\\\n",
    "             [np.abs(modele.predict([XXvalid.iloc[i]])-YYvalid.iloc[i])\\\n",
    "              for i in range(len(XXvalid)-1)]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOL5iJTlZCmM9764vTsZljv",
   "collapsed_sections": [],
   "name": "descente-deux-variables.ipynb",
   "provenance": [
    {
     "file_id": "164i4yxW6Yks9BXBhzNAJHUMyX1UBjEp3",
     "timestamp": 1606828072802
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
